{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "goznakclf2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTgLFCIRx4fL",
        "outputId": "cf227751-fd62-4d6f-b729-a07c62da1783",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QGi6wRex_70"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "from tqdm import tqdm\n",
        "import librosa.feature\n",
        "from PIL import Image\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms, datasets\n",
        "from IPython.display import clear_output\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19B74ov40vZu"
      },
      "source": [
        "def spec2image(spec, eps=1e-6):\n",
        "    mean = spec.mean()\n",
        "    std = spec.std()\n",
        "    spec_norm = (spec - mean) / (std + eps)\n",
        "    spec_min, spec_max = spec_norm.min(), spec_norm.max()\n",
        "    spec_scaled = 255 * (spec_norm - spec_min) / (spec_max - spec_min)\n",
        "    spec_scaled = spec_scaled.astype(np.uint8)\n",
        "    return spec_scaled"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbInesvG0yAz"
      },
      "source": [
        "class CLFData(torch.utils.data.Dataset):\n",
        "    def __init__(self, path_data):\n",
        "        self.path_data = path_data\n",
        "        self.class1 = os.listdir(self.path_data + 'noisy/')\n",
        "        self.class1.sort()\n",
        "        self.class2 = os.listdir(self.path_data + 'clear/')\n",
        "        self.class2.sort()\n",
        "        self.labels0 = np.zeros(len(self.class1))\n",
        "        self.labels1 = np.ones(len(self.class2))\n",
        "        self.all_paths_class1 = np.array([self.path_data + 'noisy/' + name for name in self.class1])\n",
        "        self.all_paths_class2 = np.array([self.path_data + 'clear/' + name for name in self.class2])\n",
        "        self.all_paths = np.hstack((self.all_paths_class1,self.all_paths_class2))\n",
        "        self.labels = np.hstack((self.labels0, self.labels1))\n",
        "    def __len__(self):\n",
        "        return len(self.all_paths)\n",
        "    def __getitem__(self, idx):\n",
        "        image = spec2image(np.load(self.all_paths[idx]).T)\n",
        "        if image.shape[1] <= 200:\n",
        "            image_crop = np.zeros((80,200))\n",
        "            image_crop[:image.shape[0],:image.shape[1]] = image\n",
        "        else:\n",
        "            rand_coord = np.random.randint(0, image.shape[1]-200)\n",
        "            image_crop = image[:, rand_coord:rand_coord+200]\n",
        "        image_crop = torch.FloatTensor(image_crop)\n",
        "        image_crop = image_crop.unsqueeze(0)\n",
        "        image_crop.requires_grad_(True)\n",
        "        return image_crop, torch.FloatTensor([self.labels[idx]])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1XseU0z01fi"
      },
      "source": [
        "model = models.resnet18()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qH2G9eRJThWS"
      },
      "source": [
        "model.conv1 = nn.Conv2d(1,64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "model.fc = nn.Linear(in_features=512, out_features=1, bias=True)\n",
        "model = nn.Sequential(\n",
        "    model,\n",
        "    nn.Sigmoid()\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5MAuYf_2zyn",
        "outputId": "821bbcae-0b0f-423d-b351-474850c5b156",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(model)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): ResNet(\n",
            "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Linear(in_features=512, out_features=1, bias=True)\n",
            "  )\n",
            "  (1): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqIH6Z0E21HP"
      },
      "source": [
        "train_data = CLFData('/content/gdrive/My Drive/train/')\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=256, shuffle=True)\n",
        "val_data = CLFData('/content/gdrive/My Drive/validate/')\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=len(val_data), shuffle=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y--QbVifYDV0",
        "outputId": "dbb890c1-3b30-49cd-c48a-b8e5526552d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "num_epochs = 100\n",
        "train_loss = []\n",
        "roc = []\n",
        "i = 0\n",
        "model = model.cuda()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for X_batch, y_batch in tqdm(train_loader):\n",
        "        X_batch = X_batch.cuda()\n",
        "        y_batch = y_batch.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        predict = model(X_batch)\n",
        "        loss = nn.BCELoss()(predict,y_batch)\n",
        "        loss.backward()    \n",
        "        optimizer.step()\n",
        "\n",
        "        error = loss.item()\n",
        "        train_loss.append(error)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for x, y in val_loader:\n",
        "                x = x.cuda()\n",
        "                y = y.cuda()\n",
        "                val_predict = model(x)\n",
        "\n",
        "        if i%5 == 0:\n",
        "            torch.save(model, '/content/gdrive/My Drive/resnet_model')\n",
        "        i += 1\n",
        "        clear_output(True)\n",
        "        print('Epoch: ', epoch)\n",
        "        roc.append(roc_auc_score(y.detach().cpu().numpy(), val_predict.detach().cpu().numpy().ravel()))\n",
        "        plt.figure(figsize=(10,5))\n",
        "        plt.subplot(121)\n",
        "        plt.semilogy(train_loss)\n",
        "        plt.title('Train loss')\n",
        "        plt.grid()\n",
        "        plt.subplot(122)\n",
        "        plt.plot(roc)\n",
        "        plt.title('validation ROC-AUC')\n",
        "        plt.grid()\n",
        "        plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/94 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlAhLI6WY9ON"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}